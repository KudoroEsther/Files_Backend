{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d28e49",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82abdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# from scipy import stats\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a96a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore, skew\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82edf0f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = r'https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_train.csv'\n",
    "test_url = r'https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91b8127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents Education Self_Employed  \\\n",
       "0  LP001015   Male     Yes          0  Graduate            No   \n",
       "1  LP001022   Male     Yes          1  Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5720                  0       110.0             360.0   \n",
       "1             3076               1500       126.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area  \n",
       "0             1.0         Urban  \n",
       "1             1.0         Urban  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_url, sep=\",\")\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe91f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0  Graduate            No   \n",
       "1  LP001003   Male     Yes          1  Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_url, sep=\",\")\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7647a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc92b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting datatypes\n",
    "df[\"Dependents\"] = df[\"Dependents\"].replace(\"3+\", 3)\n",
    "\n",
    "df= df.astype({\"Dependents\":\"float64\", \"ApplicantIncome\":\"float64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3458c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "Gender              13\n",
      "Married              3\n",
      "Dependents          15\n",
      "Self_Employed       32\n",
      "LoanAmount          22\n",
      "Loan_Amount_Term    14\n",
      "Credit_History      50\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows:\n",
      "Number of duplicated Rows: 0\n",
      "There are no duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "#Checking missing values\n",
    "print(\"Missing Values\")\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum()>0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values\")\n",
    "\n",
    "#Checking for duplicates\n",
    "print(\"\\nDuplicate Rows:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicated Rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates/len(duplicates))*100:.2f}%\")\n",
    "else:\n",
    "    print(\"There are no duplicate rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61013c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "df.dropna(subset=[\"LoanAmount\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bac5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Loan_Amount_Term\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b7ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "df[\"Gender\"] = df['Gender'].fillna(df[\"Gender\"].mode().iloc[0])\n",
    "df[\"Married\"] = df['Married'].fillna(df[\"Married\"].mode().iloc[0])\n",
    "df[\"Self_Employed\"] = df['Self_Employed'].fillna(df[\"Self_Employed\"].mode().iloc[0])\n",
    "\n",
    "df[\"Dependents\"] = df['Dependents'].fillna(df[\"Dependents\"].median())\n",
    "df[\"Credit_History\"] = df['Credit_History'].fillna(df[\"Credit_History\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d9801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Status_Int\"] = (df[\"Loan_Status\"] == 'Y').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b47394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_credit_history_category(c):\n",
    "    \"\"\"\n",
    "    Converts credit history to a categorical feature\n",
    "    \"\"\"\n",
    "    if c == 1:\n",
    "        return \"Good\"\n",
    "    else:\n",
    "        return \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e20cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Credit_History_Label\"] = df[\"Credit_History\"].apply(map_credit_history_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2ccd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID                 0\n",
       "Gender                  0\n",
       "Married                 0\n",
       "Dependents              0\n",
       "Education               0\n",
       "Self_Employed           0\n",
       "ApplicantIncome         0\n",
       "CoapplicantIncome       0\n",
       "LoanAmount              0\n",
       "Loan_Amount_Term        0\n",
       "Credit_History          0\n",
       "Property_Area           0\n",
       "Loan_Status             0\n",
       "Loan_Status_Int         0\n",
       "Credit_History_Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "555019bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 1 to 613\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Loan_ID               578 non-null    object \n",
      " 1   Gender                578 non-null    object \n",
      " 2   Married               578 non-null    object \n",
      " 3   Dependents            578 non-null    float64\n",
      " 4   Education             578 non-null    object \n",
      " 5   Self_Employed         578 non-null    object \n",
      " 6   ApplicantIncome       578 non-null    float64\n",
      " 7   CoapplicantIncome     578 non-null    float64\n",
      " 8   LoanAmount            578 non-null    float64\n",
      " 9   Loan_Amount_Term      578 non-null    float64\n",
      " 10  Credit_History        578 non-null    float64\n",
      " 11  Property_Area         578 non-null    object \n",
      " 12  Loan_Status           578 non-null    object \n",
      " 13  Loan_Status_Int       578 non-null    int64  \n",
      " 14  Credit_History_Label  578 non-null    object \n",
      "dtypes: float64(6), int64(1), object(8)\n",
      "memory usage: 72.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bca2e8",
   "metadata": {},
   "source": [
    "## 2. EDA-Based Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedf4ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 1 to 613\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Loan_ID               578 non-null    object \n",
      " 1   Gender                578 non-null    object \n",
      " 2   Married               578 non-null    object \n",
      " 3   Dependents            578 non-null    float64\n",
      " 4   Education             578 non-null    object \n",
      " 5   Self_Employed         578 non-null    object \n",
      " 6   ApplicantIncome       578 non-null    float64\n",
      " 7   CoapplicantIncome     578 non-null    float64\n",
      " 8   LoanAmount            578 non-null    float64\n",
      " 9   Loan_Amount_Term      578 non-null    float64\n",
      " 10  Credit_History        578 non-null    float64\n",
      " 11  Property_Area         578 non-null    object \n",
      " 12  Loan_Status           578 non-null    object \n",
      " 13  Loan_Status_Int       578 non-null    int64  \n",
      " 14  Credit_History_Label  578 non-null    object \n",
      "dtypes: float64(6), int64(1), object(8)\n",
      "memory usage: 72.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52562f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Missing Values:\n",
      "No missing values found (as expected from EDA)\n",
      "\n",
      "2. Duplicate Rows:\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "3. Skewness Analysis (EDA identified right-skewed variables):\n",
      "ApplicantIncome: skewness = 6.494 (right-skewed)\n",
      "CoapplicantIncome: skewness = 7.399 (right-skewed)\n",
      "LoanAmount: skewness = 2.643 (right-skewed)\n",
      "\n",
      "4. Correlation with Loan_Status (EDA Evidence):\n",
      "\n",
      "Low-signal features (|correlation| < 0.1):\n",
      "CoapplicantIncome: -0.070\n",
      "LoanAmount: -0.042\n",
      "Loan_Amount_Term: -0.030\n",
      "Dependents: 0.027\n",
      "ApplicantIncome: -0.006\n"
     ]
    }
   ],
   "source": [
    "df_processed = df.copy()\n",
    "\n",
    "# 1. Checking for missing values\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing_values = df_processed.isnull().sum()\n",
    "if missing_values.sum()>0:\n",
    "    print(missing_values[missing_values>0])\n",
    "else:\n",
    "    print(\"No missing values found (as expected from EDA)\")\n",
    "\n",
    "#2. Checking for duplicates\n",
    "print(\"\\n2. Duplicate Rows:\")\n",
    "duplicates = df_processed.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates/len(df_processed))*100:.2f}%\")\n",
    "\n",
    "#3. Checking for skewness for variable identified in EDA as right-skewed\n",
    "print(\"\\n3. Skewness Analysis (EDA identified right-skewed variables):\")\n",
    "skewed_vars = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"LoanAmountTerm\"]\n",
    "for var in skewed_vars:\n",
    "    if var in df_processed.columns:\n",
    "        skewness = skew(df_processed[var])\n",
    "        print(f\"{var}: skewness = {skewness:.3f} ({'right-skewed' if skewness >0.5 else 'approximately normal'})\")\n",
    "\n",
    "#4. Checking for correlation with target (EDA evidence)\n",
    "print(\"\\n4. Correlation with Loan_Status (EDA Evidence):\")\n",
    "num_features = df_processed.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_features = num_features.drop(\"Credit_History\")\n",
    "num_features = pd.DataFrame(df_processed[num_features])\n",
    "\n",
    "correlations = num_features.corr()[\"Loan_Status_Int\"].sort_values(key=abs, ascending=False)\n",
    "high_signal = correlations[abs(correlations)>0.2].drop(\"Loan_Status_Int\")\n",
    "for feature, corr in high_signal.items():\n",
    "    print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nLow-signal features (|correlation| < 0.1):\")\n",
    "low_signal = correlations[abs(correlations) < 0.1]\n",
    "for feature, corr in low_signal.items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f38f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "# num_features = num_features.drop(\"Credit_History\")\n",
    "# num_features = pd.DataFrame(df[num_features])\n",
    "# num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42e9f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status',\n",
       "       'Loan_Status_Int', 'Credit_History_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd455699",
   "metadata": {},
   "source": [
    "## 3. Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e20d58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates to remove (as expected from EDA)\n"
     ]
    }
   ],
   "source": [
    "if duplicates > 0:\n",
    "    print(f\"Removing {duplicates} duplicate rows...\")\n",
    "    df_processed = df_processed.drop_duplicates()\n",
    "    print(f\"Dataset shape after removing duplicates: {df_processed.shape}\")\n",
    "else:\n",
    "    print(\"No duplicates to remove (as expected from EDA)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a9f93",
   "metadata": {},
   "source": [
    "## 4. Log-Transform Skewed Variables (EDA Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df730c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOG-TRANSFORMING SKEWED VARIABLES ===\n",
      "EDA identified these variables as right-skewed and recommended log transformation:\n",
      "\n",
      "ApplicantIncome: Applied log transformation\n",
      "Original skewness: 6.494 → Transformed skewness: 0.465\n",
      "\n",
      "CoapplicantIncome: Applied log1p transformation (had 0.000 minimum value)\n",
      "Original skewness: 7.399 → Transformed skewness: -0.178\n",
      "\n",
      "LoanAmount: Applied log transformation\n",
      "Original skewness: 2.643 → Transformed skewness: -0.207\n",
      "\n",
      " Dataset shape after log transformation: (578, 18)\n",
      "New log-transformed columns: ['ApplicantIncome_log', 'CoapplicantIncome_log', 'LoanAmount_log']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== LOG-TRANSFORMING SKEWED VARIABLES ===\")\n",
    "print(\"EDA identified these variables as right-skewed and recommended log transformation:\")\n",
    "\n",
    "#Variables to log-transform based on EDA findings\n",
    "skewed_vars = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"LoanAmountTerm\"]\n",
    "\n",
    "for var in skewed_vars:\n",
    "    if var in df_processed.columns:\n",
    "        #Check if variable has zero or negative values\n",
    "        min_val = df_processed[var].min()\n",
    "        if min_val <= 0:\n",
    "            #Use log1p for variables with zeros\n",
    "            df_processed[f\"{var}_log\"] = np.log1p(df_processed[var])\n",
    "            print(f\"\\n{var}: Applied log1p transformation (had {min_val:.3f} minimum value)\")\n",
    "        else:\n",
    "            #use log for positive values only\n",
    "            df_processed[f\"{var}_log\"]= np.log(df_processed[var])\n",
    "            print(f\"\\n{var}: Applied log transformation\")\n",
    "        \n",
    "        #Checking skewness before and after\n",
    "        original_skew = skew(df_processed[var])\n",
    "        transformed_skew = skew(df_processed[f\"{var}_log\"])\n",
    "        print(f\"Original skewness: {original_skew:.3f} → Transformed skewness: {transformed_skew:.3f}\")\n",
    "\n",
    "print(f\"\\n Dataset shape after log transformation: {df_processed.shape}\")\n",
    "print(f\"New log-transformed columns:\", [col for col in df_processed.columns if '_log' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9eeec8",
   "metadata": {},
   "source": [
    "## 5. Outlier Treatment (EDA Recommendation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7b4bc",
   "metadata": {},
   "source": [
    "Bsed on EDA findings, handle outliers using IQR-capping method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ff8c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OUTLIER TREATMENT (IQR-CAPPING METHOD) ===\n",
      "EDA recommended IQR-capping for extreme features to preserve data points\n",
      "Treating outliers in 8 numerical features...\n",
      "\n",
      "ApplicantIncome: Capped 48 outliers\n",
      "\n",
      "CoapplicantIncome: Capped 18 outliers\n",
      "\n",
      "LoanAmount: Capped 39 outliers\n",
      "\n",
      "Loan_Amount_Term: Capped 85 outliers\n",
      "\n",
      "ApplicantIncome_log: Capped 27 outliers\n",
      "\n",
      "LoanAmount_log: Capped 34 outliers\n"
     ]
    }
   ],
   "source": [
    "# Outlier treatment based on EDA recommendations\n",
    "print(\"=== OUTLIER TREATMENT (IQR-CAPPING METHOD) ===\")\n",
    "print(\"EDA recommended IQR-capping for extreme features to preserve data points\")\n",
    "\n",
    "numerical_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if \"Loan_Status_Int\" in numerical_cols:\n",
    "    numerical_cols.remove(\"Loan_Status_Int\")\n",
    "    numerical_cols.remove(\"Credit_History\")\n",
    "print(f\"Treating outliers in {len(numerical_cols)} numerical features...\")\n",
    "\n",
    "#Applying IQR-capping method\n",
    "outliers_capped = 0\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_processed[col].quantile(0.25)\n",
    "    Q3 = df_processed[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    #Counting outliers before capping\n",
    "    outliers_before = ((df_processed[col]< lower_bound)| (df_processed[col] > upper_bound)).sum()\n",
    "    if outliers_before > 0:\n",
    "        #Cap outliers\n",
    "        df_processed[col] = np.where(df_processed[col] < lower_bound, lower_bound, df_processed[col])\n",
    "        df_processed[col] = np.where(df_processed[col]> upper_bound, upper_bound, df_processed[col])\n",
    "        outliers_capped += outliers_before\n",
    "        print(f\"\\n{col}: Capped {outliers_before} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3991ea",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482eafcb",
   "metadata": {},
   "source": [
    "Encode Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e996ca55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#This a binary category (we can have label or binary encoding)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m le = \u001b[43mLabelEncoder\u001b[49m()\n\u001b[32m      4\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mgender_encoded\u001b[39m\u001b[33m\"\u001b[39m] = le.fit_transform(df[\u001b[33m\"\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#Viewing the encoded data against the actual data\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "#This a binary category (we can have label or binary encoding)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"gender_encoded\"] = le.fit_transform(df[\"Gender\"])\n",
    "\n",
    "#Viewing the encoded data against the actual data\n",
    "df[[\"gender_encoded\", \"Gender\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Graduate', 'Not Graduate'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Education'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
